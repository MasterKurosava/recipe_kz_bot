from aiogram import Router, F
from aiogram.types import Message
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from typing import Annotated
from keyboards import get_main_menu, get_cancel_button, get_back_to_menu_button
from services.recipe_service import get_recipe_history
import asyncpg

router = Router()


class HistoryStates(StatesGroup):
    waiting_for_recipe_id = State()


@router.message(F.text == "ğŸ•“ Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¿Ğ¾ Ñ€ĞµÑ†ĞµĞ¿Ñ‚Ñƒ")
async def cmd_recipe_history(message: Message, state: FSMContext):
    """ĞĞ°Ñ‡Ğ°Ğ»Ğ¾ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ¿Ğ¾ Ñ€ĞµÑ†ĞµĞ¿Ñ‚Ñƒ"""
    await message.answer(
        "ğŸ•“ Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ ID Ñ€ĞµÑ†ĞµĞ¿Ñ‚Ğ° Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€Ğ° Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸:",
        reply_markup=get_cancel_button()
    )
    await state.set_state(HistoryStates.waiting_for_recipe_id)


@router.message(HistoryStates.waiting_for_recipe_id)
async def process_recipe_id_history(
    message: Message, 
    state: FSMContext,
    db_pool: Annotated[asyncpg.Pool, "db_pool"]
):
    """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ²Ğ²ĞµĞ´Ñ‘Ğ½Ğ½Ğ¾Ğ³Ğ¾ ID Ñ€ĞµÑ†ĞµĞ¿Ñ‚Ğ° Ğ´Ğ»Ñ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸"""
    if message.text == "âŒ ĞÑ‚Ğ¼ĞµĞ½Ğ°" or message.text == "ğŸ”™ Ğ’ Ğ¼ĞµĞ½Ñ":
        await state.clear()
        await message.answer(
            "âŒ ĞŸÑ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ¾Ñ‚Ğ¼ĞµĞ½Ñ‘Ğ½." if message.text == "âŒ ĞÑ‚Ğ¼ĞµĞ½Ğ°" else "",
            reply_markup=get_main_menu()
        )
        return

    recipe_id = message.text.strip()

    if not recipe_id:
        await message.answer("âš ï¸ ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ²Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ñ‹Ğ¹ ID Ñ€ĞµÑ†ĞµĞ¿Ñ‚Ğ°:")
        return

    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ pool Ğ¸Ğ· middleware data
    pool = db_pool

    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ñ€ĞµÑ†ĞµĞ¿Ñ‚Ğ°
    history = await get_recipe_history(recipe_id, pool)

    if not history:
        await message.answer(
            f"ğŸ“­ Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¿Ğ¾ Ñ€ĞµÑ†ĞµĞ¿Ñ‚Ñƒ `{recipe_id}` Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°.",
            reply_markup=get_back_to_menu_button(),
            parse_mode="Markdown"
        )
    else:
        # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ñ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸ĞµĞ¹
        history_text = f"ğŸ“‹ Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¿Ğ¾ Ñ€ĞµÑ†ĞµĞ¿Ñ‚Ñƒ: `{recipe_id}`\n\n"
        
        for i, record in enumerate(history, 1):
            date_str = record['created_at'].strftime("%d.%m.%Y %H:%M")
            comment = record['comment'] if record['comment'] else "ĞĞµÑ‚ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ñ"
            user_id = record['user_id']
            
            history_text += f"ğŸ“Œ Ğ—Ğ°Ğ¿Ğ¸ÑÑŒ #{i}\n"
            history_text += f"ğŸ“… Ğ”Ğ°Ñ‚Ğ°: {date_str}\n"
            history_text += f"ğŸ’¬ ĞšĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¹: {comment}\n"
            history_text += f"ğŸ‘¤ Ğ’Ğ½Ñ‘Ñ: {user_id}\n\n"

        # Telegram Ğ¸Ğ¼ĞµĞµÑ‚ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚ Ğ½Ğ° Ğ´Ğ»Ğ¸Ğ½Ñƒ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ (4096 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²)
        if len(history_text) > 4096:
            # Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ½Ğ° Ñ‡Ğ°ÑÑ‚Ğ¸
            chunks = []
            current_chunk = ""
            for line in history_text.split('\n'):
                if len(current_chunk + line + '\n') > 4000:
                    chunks.append(current_chunk)
                    current_chunk = line + '\n'
                else:
                    current_chunk += line + '\n'
            if current_chunk:
                chunks.append(current_chunk)
            
            for chunk in chunks:
                await message.answer(
                    chunk,
                    reply_markup=get_back_to_menu_button() if chunk == chunks[-1] else None,
                    parse_mode="Markdown"
                )
        else:
            await message.answer(
                history_text,
                reply_markup=get_back_to_menu_button(),
                parse_mode="Markdown"
            )

    await state.clear()
